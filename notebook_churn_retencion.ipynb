{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d45d312f",
   "metadata": {},
   "source": [
    "# üìä Proyecto de Ciencia de Datos para Empresa de Suscripciones  \n",
    "## Predicci√≥n de Fuga de Clientes (Customer Churn) y Priorizaci√≥n de Retenci√≥n\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Contexto de negocio y motivaci√≥n estrat√©gica\n",
    "\n",
    "Este proyecto representa el caso de una **empresa real de servicios por suscripci√≥n** (por ejemplo, telecom / SaaS B2C/B2B) que:\n",
    "\n",
    "- Ofrece planes **mensuales** y **anuales**.\n",
    "- Comercializa varios servicios: internet, telefon√≠a, servicios adicionales.\n",
    "- Factura de forma **recurrente** por cliente, generando un **MRR (Monthly Recurring Revenue)** estable.\n",
    "\n",
    "La direcci√≥n detect√≥ problemas claros:\n",
    "\n",
    "- La **tasa de churn** (clientes que cancelan el servicio) ha ido en aumento.\n",
    "- No existe un mecanismo **predictivo** para anticipar qu√© clientes est√°n en riesgo.\n",
    "- Las campa√±as de retenci√≥n se ejecutan de forma **masiva** y poco enfocada:\n",
    "  - Alto costo en descuentos y llamadas.\n",
    "  - Bajo impacto real en reducci√≥n de fuga.\n",
    "\n",
    "A nivel financiero, esto se traduce en:\n",
    "\n",
    "- Menor **LTV (Lifetime Value)** de los clientes.\n",
    "- Mayor presi√≥n en **Adquisici√≥n de Clientes (CAC)** para compensar los que se van.\n",
    "- Dificultad para planear crecimiento y capacidad operativa.\n",
    "\n",
    "---\n",
    "\n",
    "### Pregunta de negocio\n",
    "\n",
    "> **¬øPodemos construir un modelo de riesgo de churn que permita priorizar a qu√© clientes contactar y qu√© segmentos requieren acciones estructurales de mejora del servicio?**\n",
    "\n",
    "---\n",
    "\n",
    "### Objetivos de negocio\n",
    "\n",
    "1. **Cuantificar el churn actual** y entender sus drivers principales.\n",
    "2. Entrenar un **modelo de clasificaci√≥n** que estime la probabilidad de churn por cliente.\n",
    "3. Generar una **lista priorizada** de clientes de alto riesgo para campa√±as de retenci√≥n.\n",
    "4. Traducir los resultados a **recomendaciones accionables** para:\n",
    "   - Customer Success y Retenci√≥n.\n",
    "   - Marketing (ofertas, campa√±as).\n",
    "   - Operaciones y Experiencia de Cliente (mejora de servicio).\n",
    "\n",
    "---\n",
    "\n",
    "### M√©tricas clave para evaluar la soluci√≥n\n",
    "\n",
    "- **F1-score de la clase churn**: equilibrio entre precisi√≥n y recall.\n",
    "- **Recall de la clase churn**: qu√© proporci√≥n de clientes que realmente se van logramos identificar.\n",
    "- **ROC-AUC**: capacidad del modelo para separar churn vs no churn.\n",
    "- **Lift en el top 10‚Äì20%** de clientes ordenados por riesgo:\n",
    "  - ¬øQu√© tanto aumenta la tasa de churn en el segmento priorizado vs la tasa global?\n",
    "\n",
    "---\n",
    "\n",
    "> Este notebook est√° dise√±ado para ser presentado a un **director de Retenci√≥n/Customer Success** o a la **Direcci√≥n de Datos**, mostrando un flujo completo de trabajo con foco en impacto de negocio y no solo en m√©tricas t√©cnicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95abeef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ C√≥digo ‚Äì Imports y configuraci√≥n global\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Configuraci√≥n est√©tica\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.3f}\")\n",
    "sns.set(style=\"whitegrid\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Entorno preparado. Listo para cargar datos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb96aa",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Carga del dataset desde Excel y perfilado inicial\n",
    "\n",
    "Trabajaremos con un dataset de producci√≥n exportado a Excel:\n",
    "\n",
    "> `churn_clientes_sintetico_40k.xlsx`\n",
    "\n",
    "Este dataset representa el hist√≥rico reciente de clientes de la empresa, con columnas como:\n",
    "\n",
    "- Identificador y antig√ºedad (`customer_id`, `tenure_months`).\n",
    "- Segmento y tipo de contrato (`segment`, `contract_type`).\n",
    "- Servicios contratados (`has_internet`, `has_phone`, `num_services`).\n",
    "- Facturaci√≥n (`monthly_charges`, `total_charges`).\n",
    "- Soporte y pagos (`num_tickets_6m`, `late_payments_6m`, `has_discount`).\n",
    "- M√©todo de pago (`payment_method`).\n",
    "- Variable objetivo (`churn` = 1 si el cliente abandon√≥ el servicio).\n",
    "\n",
    "En este punto:\n",
    "\n",
    "- Verificamos tama√±o del dataset.\n",
    "- Revisamos tipos de datos.\n",
    "- Cuantificamos valores faltantes.\n",
    "- Medimos la tasa actual de churn.\n",
    "\n",
    "Esto ya da valor al negocio porque responde:  \n",
    "**‚Äú¬øDe qu√© tama√±o es el problema y qu√© tan balanceada est√° la base?‚Äù**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ C√≥digo ‚Äì Carga de datos y chequeos b√°sicos\n",
    "\n",
    "FILE_PATH = \"churn_clientes_sintetico_40k.xlsx\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(FILE_PATH)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No se encontr√≥ el archivo '{FILE_PATH}'. \"\n",
    "        \"Aseg√∫rate de que est√© en la misma carpeta que este notebook.\"\n",
    "    )\n",
    "\n",
    "n_rows, n_cols = df.shape\n",
    "\n",
    "print(f\"üìÇ Dataset cargado correctamente: {n_rows:,} filas, {n_cols} columnas\\n\")\n",
    "\n",
    "print(\"üîé Vista r√°pida de las primeras filas:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n‚ÑπÔ∏è Informaci√≥n de tipos de datos:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n‚ùó Porcentaje de valores faltantes por columna:\")\n",
    "missing_pct = df.isna().mean().sort_values(ascending=False) * 100\n",
    "display(missing_pct)\n",
    "\n",
    "# Distribuci√≥n de la variable objetivo\n",
    "if 'churn' not in df.columns:\n",
    "    raise ValueError(\"La columna 'churn' no existe en el dataset. Verifica el archivo de entrada.\")\n",
    "\n",
    "churn_dist = df['churn'].value_counts(normalize=True).rename('proportion')\n",
    "print(\"\\nüìä Distribuci√≥n de churn (0=se queda, 1=se va):\")\n",
    "display(churn_dist.to_frame())\n",
    "\n",
    "churn_rate = churn_dist.get(1, 0)\n",
    "print(f\"‚û°Ô∏è Tasa global de churn en la muestra: {churn_rate:.3%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3356a279",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Calidad de datos: duplicados, faltantes y consistencia\n",
    "\n",
    "Antes de modelar, debemos asegurar una base de calidad m√≠nima:\n",
    "\n",
    "1. **Duplicados de cliente**  \n",
    "   - En entornos reales, es com√∫n tener duplicados por errores de integraci√≥n.\n",
    "   - Como regla, nos quedamos con **la primera ocurrencia** por `customer_id`.\n",
    "\n",
    "2. **Valores faltantes**  \n",
    "   - Variables num√©ricas: imputamos con **mediana** (robusto a outliers).\n",
    "   - Variables categ√≥ricas: imputamos con la **moda** (valor m√°s frecuente).\n",
    "\n",
    "3. **Consistencia b√°sica**  \n",
    "   - No deber√≠a haber cargos negativos.\n",
    "   - El n√∫mero de servicios debe ser mayor o igual a 1.\n",
    "\n",
    "Adem√°s, guardaremos algunos indicadores de calidad para documentar el estado del dato.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f67244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ C√≥digo ‚Äì Limpieza de duplicados y valores faltantes\n",
    "\n",
    "# Comprobaci√≥n de duplicados por customer_id\n",
    "if 'customer_id' in df.columns:\n",
    "    dup_count = df['customer_id'].duplicated().sum()\n",
    "    print(f\"üß¨ Registros duplicados por 'customer_id': {dup_count:,}\")\n",
    "    if dup_count > 0:\n",
    "        df = df.drop_duplicates(subset='customer_id', keep='first')\n",
    "        print(f\"‚úÖ Se eliminaron duplicados. Nuevas filas: {len(df):,}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No existe columna 'customer_id'. Se asume que cada fila es un cliente √∫nico.\")\n",
    "\n",
    "# Identificar columnas num√©ricas y categ√≥ricas (excluyendo target)\n",
    "target_col = 'churn'\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns.drop(target_col)\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "print(\"\\nüìå Columnas num√©ricas:\", list(numeric_cols))\n",
    "print(\"üìå Columnas categ√≥ricas:\", list(categorical_cols))\n",
    "\n",
    "# Imputaci√≥n de valores faltantes\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Num√©ricos ‚Üí mediana\n",
    "for col in numeric_cols:\n",
    "    median_val = df_clean[col].median()\n",
    "    missing_before = df_clean[col].isna().sum()\n",
    "    df_clean[col].fillna(median_val, inplace=True)\n",
    "    if missing_before > 0:\n",
    "        print(f\"‚úÖ Imputados {missing_before} valores faltantes en '{col}' con mediana={median_val:.2f}\")\n",
    "\n",
    "# Categ√≥ricos ‚Üí moda\n",
    "for col in categorical_cols:\n",
    "    mode_val = df_clean[col].mode().iloc[0]\n",
    "    missing_before = df_clean[col].isna().sum()\n",
    "    df_clean[col].fillna(mode_val, inplace=True)\n",
    "    if missing_before > 0:\n",
    "        print(f\"‚úÖ Imputados {missing_before} valores faltantes en '{col}' con moda='{mode_val}'\")\n",
    "\n",
    "print(\"\\n‚úÖ Porcentaje de valores faltantes despu√©s de limpieza:\")\n",
    "display(df_clean.isna().mean().sort_values(ascending=False) * 100)\n",
    "\n",
    "# Reglas de consistencia simples\n",
    "if 'monthly_charges' in df_clean.columns:\n",
    "    negativos = (df_clean['monthly_charges'] < 0).sum()\n",
    "    if negativos > 0:\n",
    "        print(f\"‚ö†Ô∏è Se encontraron {negativos} monthly_charges negativos. Se pasar√°n a NaN y se imputar√°n con la mediana.\")\n",
    "        df_clean.loc[df_clean['monthly_charges'] < 0, 'monthly_charges'] = np.nan\n",
    "        median_val = df_clean['monthly_charges'].median()\n",
    "        df_clean['monthly_charges'].fillna(median_val, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b341d",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Exploraci√≥n descriptiva: tama√±o del problema y estructura de la base\n",
    "\n",
    "En esta secci√≥n:\n",
    "\n",
    "- Cuantificamos el churn por segmentos clave:\n",
    "  - Tipo de contrato.\n",
    "  - Segmento de cliente.\n",
    "  - M√©todo de pago.\n",
    "- Observamos la distribuci√≥n de variables num√©ricas relevantes:\n",
    "  - Antig√ºedad.\n",
    "  - Cargos mensuales.\n",
    "  - Tickets y pagos tard√≠os.\n",
    "\n",
    "El objetivo es entender **d√≥nde se concentra el problema** antes de entrenar ning√∫n modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£ C√≥digo ‚Äì EDA descriptiva\n",
    "\n",
    "df_eda = df_clean.copy()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "if 'tenure_months' in df_eda.columns:\n",
    "    axes[0, 0].hist(df_eda['tenure_months'], bins=30)\n",
    "    axes[0, 0].set_title('Distribuci√≥n de antig√ºedad (tenure_months)')\n",
    "    axes[0, 0].set_xlabel('Meses')\n",
    "    axes[0, 0].set_ylabel('Frecuencia')\n",
    "\n",
    "if 'monthly_charges' in df_eda.columns:\n",
    "    axes[0, 1].hist(df_eda['monthly_charges'], bins=30)\n",
    "    axes[0, 1].set_title('Distribuci√≥n de cargos mensuales')\n",
    "    axes[0, 1].set_xlabel('Monto mensual')\n",
    "    axes[0, 1].set_ylabel('Frecuencia')\n",
    "\n",
    "if 'num_tickets_6m' in df_eda.columns:\n",
    "    axes[1, 0].hist(df_eda['num_tickets_6m'], bins=11)\n",
    "    axes[1, 0].set_title('Tickets de soporte √∫ltimos 6 meses')\n",
    "    axes[1, 0].set_xlabel('N√∫mero de tickets')\n",
    "    axes[1, 0].set_ylabel('Frecuencia')\n",
    "\n",
    "if 'late_payments_6m' in df_eda.columns:\n",
    "    axes[1, 1].hist(df_eda['late_payments_6m'], bins=7)\n",
    "    axes[1, 1].set_title('Pagos tard√≠os √∫ltimos 6 meses')\n",
    "    axes[1, 1].set_xlabel('N√∫mero de pagos tard√≠os')\n",
    "    axes[1, 1].set_ylabel('Frecuencia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "def churn_rate_by(col):\n",
    "    if col not in df_eda.columns:\n",
    "        print(f\"‚ö†Ô∏è La columna '{col}' no existe en el dataset.\")\n",
    "        return None\n",
    "    grp = df_eda.groupby(col)['churn'].mean().sort_values(ascending=False)\n",
    "    print(f\"\\nüìä Tasa de churn por '{col}':\")\n",
    "    display(grp.to_frame('churn_rate'))\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    grp.plot(kind='bar')\n",
    "    plt.title(f'Tasa de churn por {col}')\n",
    "    plt.ylabel('Proporci√≥n de churn')\n",
    "    plt.show()\n",
    "    return grp\n",
    "\n",
    "churn_by_contract = churn_rate_by('contract_type') if 'contract_type' in df_eda.columns else None\n",
    "churn_by_segment = churn_rate_by('segment') if 'segment' in df_eda.columns else None\n",
    "churn_by_payment = churn_rate_by('payment_method') if 'payment_method' in df_eda.columns else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c27e985",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Feature engineering: enriquecer la visi√≥n del cliente\n",
    "\n",
    "Para que el modelo capture mejor el comportamiento real, creamos variables derivadas:\n",
    "\n",
    "- `tenure_years`: antig√ºedad en a√±os.\n",
    "- `is_new_customer`: indicador de clientes de **alta fragilidad** (‚â§ 6 meses).\n",
    "- `avg_charge_per_service`: ticket promedio por servicio contratado.\n",
    "- `has_many_tickets`: indicador de clientes con **alta fricci√≥n operativa**.\n",
    "- `estimated_12m_revenue`: ingreso estimado de los pr√≥ximos 12 meses *si el cliente se quedara*.\n",
    "\n",
    "Estas variables permiten hablar de **riesgo econ√≥mico**, no solo probabilidades abstractas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5Ô∏è‚É£ C√≥digo ‚Äì Feature engineering\n",
    "\n",
    "df_fe = df_clean.copy()\n",
    "\n",
    "if 'tenure_months' in df_fe.columns:\n",
    "    df_fe['tenure_years'] = df_fe['tenure_months'] / 12.0\n",
    "    df_fe['is_new_customer'] = (df_fe['tenure_months'] <= 6).astype(int)\n",
    "else:\n",
    "    df_fe['tenure_years'] = np.nan\n",
    "    df_fe['is_new_customer'] = 0\n",
    "\n",
    "if 'num_services' in df_fe.columns:\n",
    "    df_fe['num_services_clean'] = df_fe['num_services'].replace(0, 1)\n",
    "else:\n",
    "    df_fe['num_services_clean'] = 1\n",
    "\n",
    "if 'monthly_charges' in df_fe.columns:\n",
    "    df_fe['avg_charge_per_service'] = df_fe['monthly_charges'] / df_fe['num_services_clean']\n",
    "    df_fe['estimated_12m_revenue'] = df_fe['monthly_charges'] * 12\n",
    "else:\n",
    "    df_fe['avg_charge_per_service'] = np.nan\n",
    "    df_fe['estimated_12m_revenue'] = np.nan\n",
    "\n",
    "if 'num_tickets_6m' in df_fe.columns:\n",
    "    df_fe['has_many_tickets'] = (df_fe['num_tickets_6m'] >= 3).astype(int)\n",
    "else:\n",
    "    df_fe['has_many_tickets'] = 0\n",
    "\n",
    "new_cols = ['tenure_years', 'is_new_customer', 'avg_charge_per_service',\n",
    "            'estimated_12m_revenue', 'has_many_tickets']\n",
    "\n",
    "print(\"‚úÖ Columnas generadas:\")\n",
    "display(df_fe[new_cols].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac3a53",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Preparaci√≥n para modelado: separaci√≥n Train/Test y pipeline\n",
    "\n",
    "En un entorno de producci√≥n es fundamental:\n",
    "\n",
    "- Separar un conjunto de **entrenamiento** y otro de **prueba**.\n",
    "- Evitar fugas de informaci√≥n (data leakage).\n",
    "- Dejar el flujo listo para ser **empaquetado y versionado**.\n",
    "\n",
    "En esta secci√≥n:\n",
    "\n",
    "1. Definimos:\n",
    "   - `X`: variables explicativas.\n",
    "   - `y`: variable objetivo (`churn`).\n",
    "2. Separamos Train/Test con estratificaci√≥n en churn.\n",
    "3. Definimos un **pipeline de sklearn** con:\n",
    "   - `ColumnTransformer` para:\n",
    "     - Dejar num√©ricos como est√°n.\n",
    "     - One-hot encoding de categ√≥ricos.\n",
    "   - Modelo `RandomForestClassifier` como estimador principal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eee731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6Ô∏è‚É£ C√≥digo ‚Äì Train/Test split y construcci√≥n de pipeline\n",
    "\n",
    "TARGET_COL = 'churn'\n",
    "ID_COL = 'customer_id' if 'customer_id' in df_fe.columns else None\n",
    "\n",
    "if TARGET_COL not in df_fe.columns:\n",
    "    raise ValueError(\"No se encuentra la columna 'churn' en el dataset.\")\n",
    "\n",
    "y = df_fe[TARGET_COL]\n",
    "\n",
    "feature_cols = df_fe.columns.drop([TARGET_COL] + ([ID_COL] if ID_COL else []))\n",
    "X = df_fe[feature_cols]\n",
    "\n",
    "print(f\"üìê X shape: {X.shape}, y length: {len(y)}\")\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"\\nüìå Features num√©ricos:\", numeric_features)\n",
    "print(\"üìå Features categ√≥ricos:\", categorical_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nüîÄ Train: {X_train.shape[0]:,} filas  |  Test: {X_test.shape[0]:,} filas\")\n",
    "\n",
    "numeric_transformer = 'passthrough'\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_transformer, numeric_features),\n",
    "        ('categorical', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=8,\n",
    "    random_state=42,\n",
    "    class_weight='balanced_subsample',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', rf_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline preparado (preprocesamiento + modelo).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c575b3f",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ L√≠nea base (baseline): modelo Dummy\n",
    "\n",
    "Antes de dar por bueno cualquier modelo, medimos una **l√≠nea base**:\n",
    "\n",
    "- Usamos un `DummyClassifier` con estrategia **estratificada**.\n",
    "- Este modelo ‚Äúpredice al azar‚Äù respetando la proporci√≥n de churn/no churn.\n",
    "\n",
    "La regla es simple:\n",
    "\n",
    "> **Si tu modelo no supera al Dummy, no tienes modelo.**\n",
    "\n",
    "Evaluaremos:\n",
    "\n",
    "- Accuracy\n",
    "- Precision (churn=1)\n",
    "- Recall (churn=1)\n",
    "- F1\n",
    "- ROC-AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8771fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7Ô∏è‚É£ C√≥digo ‚Äì Baseline Dummy\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy='stratified', random_state=42)\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "y_proba_dummy = dummy_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_proba, name='modelo'):\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'roc_auc': roc_auc_score(y_true, y_proba)\n",
    "    }\n",
    "    print(f\"\\nüìä M√©tricas para {name}:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k:10s}: {v:.3f}\")\n",
    "    return metrics\n",
    "\n",
    "metrics_dummy = evaluate_model(y_test, y_pred_dummy, y_proba_dummy, name='Dummy (baseline)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c6dd9",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Entrenamiento del modelo de churn (Random Forest)\n",
    "\n",
    "Ahora entrenamos el modelo real:\n",
    "\n",
    "- `RandomForestClassifier` encapsulado en el **pipeline** (preprocesa + entrena).\n",
    "- Se entrena √∫nicamente con el set de entrenamiento.\n",
    "- Se eval√∫a sobre el set de prueba y se comparan las m√©tricas contra el Dummy.\n",
    "\n",
    "Buscamos:\n",
    "\n",
    "- Mejor F1 y ROC-AUC que la baseline.\n",
    "- Un Recall razonable para churn, para no dejar escapar demasiados clientes que realmente se van.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01aefa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8Ô∏è‚É£ C√≥digo ‚Äì Entrenamiento y evaluaci√≥n del modelo principal\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = model_pipeline.predict(X_test)\n",
    "y_proba_rf = model_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics_rf = evaluate_model(y_test, y_pred_rf, y_proba_rf, name='Random Forest (pipeline)')\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'metric': ['accuracy', 'precision', 'recall', 'f1', 'roc_auc'],\n",
    "    'dummy': [\n",
    "        metrics_dummy['accuracy'],\n",
    "        metrics_dummy['precision'],\n",
    "        metrics_dummy['recall'],\n",
    "        metrics_dummy['f1'],\n",
    "        metrics_dummy['roc_auc'],\n",
    "    ],\n",
    "    'random_forest': [\n",
    "        metrics_rf['accuracy'],\n",
    "        metrics_rf['precision'],\n",
    "        metrics_rf['recall'],\n",
    "        metrics_rf['f1'],\n",
    "        metrics_rf['roc_auc'],\n",
    "    ],\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Comparativa Dummy vs Random Forest:\")\n",
    "display(comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b59484",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Matriz de confusi√≥n y diagn√≥stico de errores\n",
    "\n",
    "Adem√°s de las m√©tricas agregadas, es clave entender **c√≥mo se equivoca el modelo**:\n",
    "\n",
    "- ¬øCu√°ntos clientes que se iban no se detectan? (falsos negativos).\n",
    "- ¬øCu√°ntos clientes se marcan err√≥neamente como en riesgo? (falsos positivos).\n",
    "\n",
    "Mostraremos la **matriz de confusi√≥n** en valores absolutos y normalizados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c34f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9Ô∏è‚É£ C√≥digo ‚Äì Matriz de confusi√≥n\n",
    "\n",
    "def plot_confusion_matrix_custom(y_true, y_pred, labels=(0, 1)):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "    axes[0].set_title('Matriz de confusi√≥n (absoluta)')\n",
    "    axes[0].set_xlabel('Predicci√≥n')\n",
    "    axes[0].set_ylabel('Real')\n",
    "\n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', ax=axes[1])\n",
    "    axes[1].set_title('Matriz de confusi√≥n (normalizada)')\n",
    "    axes[1].set_xlabel('Predicci√≥n')\n",
    "    axes[1].set_ylabel('Real')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix_custom(y_test, y_pred_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9248e188",
   "metadata": {},
   "source": [
    "## üîü Interpretabilidad: variables clave que explican el churn\n",
    "\n",
    "Un modelo es √∫til en negocio cuando adem√°s de predecir, **explica el fen√≥meno**.\n",
    "\n",
    "En esta secci√≥n:\n",
    "\n",
    "- Extraemos la **importancia de caracter√≠sticas** del Random Forest.\n",
    "- Identificamos las Top N variables que m√°s peso tienen en la decisi√≥n.\n",
    "- Relacionamos estas variables con acciones de negocio:\n",
    "  - Tipo de contrato.\n",
    "  - Tickets de soporte.\n",
    "  - Pagos tard√≠os.\n",
    "  - Antig√ºedad y descuentos.\n",
    "\n",
    "Esto permite contestar preguntas como:\n",
    "\n",
    "> ‚Äú¬øQu√© palancas debemos mover para reducir el churn estructuralmente?‚Äù\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîü C√≥digo ‚Äì Importancia de variables\n",
    "\n",
    "rf_fitted = model_pipeline.named_steps['model']\n",
    "preprocessor_fitted = model_pipeline.named_steps['preprocessor']\n",
    "\n",
    "numeric_feature_names = numeric_features\n",
    "cat_ohe = preprocessor_fitted.named_transformers_['categorical']\n",
    "cat_feature_names = cat_ohe.get_feature_names_out(categorical_features)\n",
    "\n",
    "all_feature_names = list(numeric_feature_names) + list(cat_feature_names)\n",
    "\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': all_feature_names,\n",
    "    'importance': rf_fitted.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "top_n = 20\n",
    "print(f\"üèÜ Top {top_n} variables m√°s importantes:\")\n",
    "display(feature_importances.head(top_n))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.barplot(\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    data=feature_importances.head(top_n)\n",
    ")\n",
    "plt.title(f'Top {top_n} caracter√≠sticas m√°s importantes')\n",
    "plt.xlabel('Importancia')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6ef71",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Ranking de clientes por riesgo y simulaci√≥n de campa√±a de retenci√≥n\n",
    "\n",
    "Con el modelo entrenado podemos construir un **score de riesgo de churn por cliente**:\n",
    "\n",
    "1. Calculamos la probabilidad de churn para cada cliente en el conjunto de test.\n",
    "2. Ordenamos de mayor a menor riesgo.\n",
    "3. Definimos un segmento prioritario, por ejemplo:\n",
    "   - Top 10% de clientes por probabilidad de churn.\n",
    "4. Medimos:\n",
    "   - Tasa de churn real dentro de ese top.\n",
    "   - `Lift` respecto a la tasa global.\n",
    "   - Ingreso estimado en riesgo (usando `estimated_12m_revenue`).\n",
    "\n",
    "Esto permite estimar el **impacto econ√≥mico** de una campa√±a focalizada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a956845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£1Ô∏è‚É£ C√≥digo ‚Äì Ranking y simulaci√≥n de campa√±a\n",
    "\n",
    "proba_test = model_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "df_test_business = df_fe.loc[X_test.index].copy()\n",
    "df_test_business['churn_real'] = y_test\n",
    "df_test_business['prob_churn_model'] = proba_test\n",
    "\n",
    "df_ranked = df_test_business.sort_values(by='prob_churn_model', ascending=False)\n",
    "\n",
    "top_pct = 0.10\n",
    "top_n_clients = int(len(df_ranked) * top_pct)\n",
    "df_top = df_ranked.head(top_n_clients)\n",
    "\n",
    "global_churn_rate = df_ranked['churn_real'].mean()\n",
    "top_churn_rate = df_top['churn_real'].mean()\n",
    "lift_top = top_churn_rate / global_churn_rate if global_churn_rate > 0 else np.nan\n",
    "\n",
    "revenue_col = 'estimated_12m_revenue'\n",
    "if revenue_col in df_top.columns:\n",
    "    total_revenue_risk = df_top.loc[df_top['churn_real'] == 1, revenue_col].sum()\n",
    "else:\n",
    "    total_revenue_risk = np.nan\n",
    "\n",
    "print(f\"üéØ Tama√±o conjunto Test: {len(df_ranked):,} clientes\")\n",
    "print(f\"üéØ Top {top_pct:.0%} de riesgo: {top_n_clients:,} clientes\\n\")\n",
    "\n",
    "print(f\"üìà Tasa de churn global en Test:      {global_churn_rate:.2%}\")\n",
    "print(f\"üî• Tasa de churn en Top {top_pct:.0%}: {top_churn_rate:.2%}\")\n",
    "print(f\"üí° Lift (Top vs Global):              {lift_top:.2f}x\")\n",
    "\n",
    "if not np.isnan(total_revenue_risk):\n",
    "    print(f\"\\nüí∞ Ingreso anual estimado en riesgo dentro del Top (clientes que efectivamente se fueron):\")\n",
    "    print(f\"   ‚âà {total_revenue_risk:,.0f} unidades monetarias\")\n",
    "\n",
    "print(\"\\nüëÄ Muestra de clientes priorizados (Top 10):\")\n",
    "cols_show = [c for c in ['customer_id', 'segment', 'contract_type', 'monthly_charges',\n",
    "                         'tenure_months', 'num_tickets_6m', 'late_payments_6m',\n",
    "                         'has_discount', 'churn_real', 'prob_churn_model'] if c in df_top.columns]\n",
    "\n",
    "display(df_top[cols_show].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb8b92",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Conclusiones ejecutivas y siguientes pasos\n",
    "\n",
    "En esta secci√≥n sintetizamos los hallazgos en lenguaje de negocio.  \n",
    "El objetivo es que un director pueda tomar decisiones sin ver el c√≥digo.\n",
    "\n",
    "El notebook imprime un **resumen ejecutivo din√°mico** basado en los resultados obtenidos:\n",
    "\n",
    "- Calidad del modelo comparado contra el baseline.\n",
    "- Variables que explican el churn.\n",
    "- Efectividad de priorizar el Top 10% de riesgo.\n",
    "- Impacto econ√≥mico potencial de actuar sobre ese segmento.\n",
    "\n",
    "Adem√°s, se listan **siguientes pasos recomendados** para evolucionar la soluci√≥n hacia producci√≥n:\n",
    "- Industrializaci√≥n del pipeline.\n",
    "- Integraci√≥n con CRM / sistema de campa√±as.\n",
    "- Monitoreo de deriva del modelo (drift).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08952fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£2Ô∏è‚É£ C√≥digo ‚Äì Resumen ejecutivo din√°mico\n",
    "\n",
    "print(\"üìå RESUMEN EJECUTIVO DEL MODELO DE CHURN\\n\")\n",
    "\n",
    "print(\"1) Desempe√±o del modelo vs baseline\\n------------------------------------\")\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "    base_val = metrics_dummy[metric]\n",
    "    rf_val = metrics_rf[metric]\n",
    "    delta = rf_val - base_val\n",
    "    print(f\"- {metric.upper():9s} | Dummy: {base_val:.3f} | RF: {rf_val:.3f} | Œî: {delta:+.3f}\")\n",
    "\n",
    "print(\"\\n2) Drivers principales de churn\\n--------------------------------\")\n",
    "for i, row in feature_importances.head(10).iterrows():\n",
    "    print(f\"- {row['feature']}: importancia {row['importance']:.3f}\")\n",
    "\n",
    "print(\"\\n3) Efectividad de la priorizaci√≥n\\n----------------------------------\")\n",
    "print(f\"- Tasa de churn global en Test:      {global_churn_rate:.2%}\")\n",
    "print(f\"- Tasa de churn en Top 10% riesgo:   {top_churn_rate:.2%}\")\n",
    "print(f\"- Lift (Top vs global):              {lift_top:.2f}x\")\n",
    "\n",
    "if not np.isnan(total_revenue_risk):\n",
    "    print(f\"- Ingreso anual estimado en riesgo dentro del Top (clientes que efectivamente se fueron):\")\n",
    "    print(f\"  ‚âà {total_revenue_risk:,.0f} unidades monetarias\")\n",
    "\n",
    "print(\"\\n4) Recomendaciones accionables\\n--------------------------------\")\n",
    "print(\"- Implementar una campa√±a de retenci√≥n espec√≠ficamente dirigida al Top 10‚Äì20% de clientes por riesgo,\")\n",
    "print(\"  combinando beneficios econ√≥micos (descuentos, upgrades) con acciones de servicio (llamadas proactivas).\")\n",
    "print(\"- Dise√±ar iniciativas estructurales para reducir la fricci√≥n en los clientes con muchos tickets de soporte.\")\n",
    "print(\"- Incentivar, mediante oferta comercial, el paso de contratos 'Month-to-month' a contratos de mayor plazo.\")\n",
    "print(\"- Revisar pol√≠ticas de cobro y recordatorio a clientes con alta incidencia de pagos tard√≠os.\")\n",
    "print(\"- Integrar este modelo al CRM para que el equipo de Customer Success trabaje con una vista priorizada de cartera.\")\n",
    "print(\"\\n‚úÖ Este notebook demuestra una soluci√≥n de ciencia de datos lista para ser discutida con negocio y escalada a producci√≥n.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
